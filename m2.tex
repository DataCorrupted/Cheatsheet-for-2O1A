\section*{Midterm 2 (Feb 28, 2020)}

\problem{
    f15m2q1
}{
    Give 1 technique that can be used to reduce the Miss Rate.
}{
    \todo
}

\problem{
    f15m2q2
}{
    Give 1 technique that can be used to reduce the Hit Time.
}{
    \todo
}

\problem{
    f14m2q4
    f15m2q5
}{
    What does ROB stand for, and why is it used in modern advanced pipelines? 
}{
    Reorder Buffer. 

    It can dynamically execute code while maintaining a precise interrupt.
}

\problem{
    f16m2q1
}{
    Writes to a cache are inherently slower than reads from a cache - why?
}{
     Read can do check tags and read data in parallel. However, write is inherently serial / sequential, so we have to check tags before writing the data to the cache. 
}

\problem{
    f14m2q1
    f15m2q3
    f16m2q2
    w12m2q10
}{
    What is the primary difference between Tomasulo’s algorithm and Scoreboarding?
}{
    Tomasulo’s: distributed; scoreboarding: centralized.

    \warn{Common data bus(CDB)}
}

\problem{
    f15m2q6
    f16m2q3
}{
    Compilers have trouble optimizing code that involves reads and writes to memory. Why? (The answer has nothing to do with how slow memory is - that is a different problem altogether).
}{
     Hazards through memory system makes it hard to optimize the code by compiler. Finding dependencies through memory is hard. Compilers can't calculate the physical address at compile time, only hardware knows in runtime. 
}

\problem{
    f15m2q4
    f16m2q4
}{
    What is the definition of a basic block? 
    Why is there a desire to create larger basic blocks? 
    Give one example of a way to create a bigger basic block.
}{
    A straight-line code sequence with no branches in except to the entry and no branches out except at the exit.\pg{149}

    So compilers can optimize more.

    Loop unrolling
}

\problem{
    f16m2q5
}{
    Processors have been built that were able to issue 8 instructions at a time using a fast clock. However, these processors are no longer being built - why not? Why would you choose a 3-issue machine over an 8-issue machine, if the clock rates were the same?
}{
     - 8-issue machine has more hardware and does more speculation, and thus requires lots of power. \\
     - If we don't have enough parallelism available, it will have many bubbles and waste energy \\
     Back then we don't care about that, but now the condition has changed and the energy efficiency is more significant now.
}

\problem{
    f15m2q7
    f16m2q6
}{
    Intel uses a Tournament predictor in some of their processors. 
    Describe what it is, and why it is used. 
    Your description can (and probably should) include sketches and drawings.
}{
     - A meta predictor that predicts which predictor should be used \\
     - It's used because each predictor performs differently based on the situation. For example, 2-bit predictor performs better than G-share when we jump to somewhere new. but after G-share learns, it will perform better.
}

\problem{
    f16m2q7
}{
    Why is loop unrolling a valuable optimization technique? What are 2 challenges to using it?
}{
     - It allows to make bigger basic blocks to do code scheduling \\
     - (1) more registers (2) don't know how to decide how many times to unroll
}

\problem{
    f12m2q10
    f14m2p2
    f15m2q8
    f16m2q8
}{
    The book states that slow and wide architectures can be more power-efficient than fast and narrow architectures. 
    Explain why. 
    Also, explain the underlying assumption that is being made, and why it is that we are still making narrow fast machines.
}{
    Slow and wide can lower both clock rate and voltage.
    Lowering $V$ and $f$ means the power goes down since $P = C \cdot f \cdot V^2$.

    If there is enough data-level parallelism, then slow and wide can provide the same throughput as fast and narrow while using less power. 
    There is not always enough DLP though.
}

\problem{
    f16m2q9
}{
    Supporting precise interrupts in machines that allow out of order completion is a challenge. Briefly explain what a precise interrupt is, why it is a challenge in OOO machines, and describe the main technique used today to provide precise interrupts.
}{
     - It is the interruption when all the instructions before the interrupt have completed, but none afterwards. \\
     - it is a challenge because ??? \\
     -  technique: reorder buffer (ROB)
}

\problem{
    f15m2q11
    f16m2q10
}{
    Briefly outline how a Vector machine works, and what type of parallelism it is exploiting.
}{
    - There are several vector registers (VRs), fill them up. Single instruction operated on these VRs, such that the single instruction do multiple operations on elements of the VRs. \\
    - Data level parallelism.
}

\problem{
    f04m1q16
    w10m1q10
    w12f0p1
    f13f0p1
    f14m2p2
    f15m2q12
    f15f0p2
    f15f1p1
    f16m2q11
    f16f0p1
}{
    What is the primary difference between superscalar and VLIW processors? 
    Give one advantage and one disadvantage of using each approach. Compare and contrast VLIW and superscalar with two advantage and one disadvantage.
    (These have to be different - in other words, if the advantage of superscalar is X, then you can’t say a disadvantage of VLIW is that it can’t do X.)
}{
     - superscalar: hardware does dynamic scheduling  \\
       adv: better at prediction and disambiguation \\
       disadv: more power consumption \\
     - VLIW: complier does static scheduling \\ 
     	adv: simpler hardware, save cost \\
	    disadv: cannot use runtime information \\
}

\problem{
    f14m2p2
    f14f0p1
    f15m2q9
    f15f1p1
    f16m2q12
    f16f0p1
}{
    You have been writing C programs for a simple, non-pipelined machine. 
    You have recently received a promotion, and now your job is to write C programs for a heavily pipelined, high-performance processor. 
    These new programs must execute as fast as possible (the emphasis is on response time, not throughput). 
    Give at least 2 examples of things you should do differently now, and be sure to explain in detail why 
    (what is the problem you are overcoming?)
}{
    (1) avoid using pointers: pointers screw up register allocation when compiling \\
    (2) avoid using recursions: return address stack can be overflowed
    Avoiding using pointers make the biggest difference in performance, because recursion in not frequently used compared to pointers in general application
}

\problem{
    f16m2q13
    w20q5q8
}{
    (Dependencies recognization \& register substitution) 
}{
    refer to the exam
}

\problem{
    f16m2q14
}{
    (Dependencies recognization \& NOPS insertion) 
}{
    refer to the exam
}

\problem{
    f16m2q15
    w20q5q9
}{
    (Fine / Coarse scheduling) \\
    \nop
}{
    refer to the exam
}

\problem{
    f16m2q16
}{
    Assuming a 19-bit address and a 256-byte Direct Mapped cache with a linesize=2, show how an address is partitioned/interpreted by the cache.
}{
    offset = 1 bit \\
    256/2 = 128 = $2^7$  entry = 7 bits \\
    tag  = 11 bits
}

\problem{
    f16m2q17
}{
    Assuming an 19-bit address and an 80-byte 10-way Set Associative cache with a linesize=4, show how an address is partitioned/interpreted by the cache.
}{
    offset = 2 bits \\
    80/(10*4) = 2 = $2^1$  set = 1 bit \\
    tag = 16 bits
}

\problem{
    f16m2q18
}{
    Assuming an 19-bit address and a 328-byte Fully Associative cache with a linesize=8, show how an address is partitioned/interpreted by the cache.
}{
    offset = 3 bits \\
    tag = 16 bits
}

\problem{
    f16m2q19
}{
    Given a 1 Megabyte physical memory, a 22 bit Virtual address, and a page size of 1K bytes, write down the number of entries in the Page Table, and the width of each entry.
}{
   1M = $2^{20}$ \\
   1K = $2^{10}$ \\
   $(2^{20})/(2^{10}) = 2^{10} \rightarrow$ 10-bit wide \\
   PM: 10 | 10 \\
   VM: 12 | 10 \\
   $2^{12}$ entries
}

\problem{
    f16m2q20
}{
    Given a 1 Megabyte physical memory, a 34 bit Virtual address, and a page size of 2K bytes, write down the number of entries in the Page Table, and the width of each entry. Is there a problem with this configuration? If so, what is the problem?
}{
    1M = $2^{20}$ \\
    2K = $2^{11}$ \\
    $(2^{20})/(2^{11}) = 2^9 \rightarrow$ 9-bit wide \\
    PM: 9 | 11 \\
    VM: 23 | 11 \\
    $2^{23}$ entries \\
    Problem: It is too large to store in 1M physical memory. We can use two page tables. One is base, another one is secondary.
}

\problem{
    f14m2q2
}{
    Which data hazard occurs when instructions are allowed to complete out of order? 
    Which one occurs when instructions are allowed to issue out of order?
}{
    \todo
}

\problem{
    f14m2q5
}{
    Speculation is a very useful technique for improving performance. 
    However, it is not being used as extensively as it once was - why not?
}{
    \todo
}

\problem{
    f14m2q5
}{
    Compilers have trouble optimizing code that involves reads and writes to memory. Why? (The answer
has nothing to do with how slow memory is - that is a different problem altogether).
}{
    Hazards through the memory system.
}

\problem{
    f14m2q7
}{
    The book states that slow and wide architectures can be more power efficient than fast and narrow architectures. Explain why. Also, explain the underlying assumption that is being made, and why it is that we are still making narrow fast machines.
}{
    \todo
}

