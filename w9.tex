\newSection{Week 9 (Appx.B \& Chp.2, Quiz 6)}

\problem{
    f04m2q3
    w08m2q3
    f12f0p2
    w12f0p2
    f13f0p2
    f14f0p2
    f16f0p2
}{
    What is the goal of the memory hierarchy, as stated in class? 
    What two principles make it work? 
    (Two types of the same principle, actually).
}{
    \pg{72} The goal is to provide a memory system with cost per byte almost as low as the cheapest level of memory and speed almost as fast as the fastest level.
    
    \pg{72} \textit{Locality} of reference: \textit{Spacial locality} \& \textit{Temporal locality}.
}


\problem{
    w13f0p1
    w15f0p1
}{
    AMAT
}{
    Average memory access time = Hit time + Miss rate * Miss penalty
}
\problem{
    f15f0p8
    w19f0q37
}{
    Find the Average Memory Access Time (AMAT) for a processor with a 1 ns clock cycle time, a miss penalty of 20 clock cycles, a miss rate of 0.10 misses per instruction, and a cache access time (including hit detection) of 1 clock cycle. 
    Assume that the read and write miss penalties are the same and ignore other write stalls.
}{
    \begin{align*}
        \texttt{AMAT} & = \texttt{Hit time} + \texttt{Miss rate} * \texttt{Miss penalty} \\
                      & = 1 \texttt{ clock} * 1 \texttt{ ns/clock} + 0.10 * 20 \texttt{ clock(s)} * 1 \texttt{ ns/clock}  \\
                      & = 3 \texttt{ ns}
    \end{align*}
}

\problem{
    f12m2q5
    f13m2q3
}{
    Roofline plots what vs what? 
    Why is this information important?
}{
    Arithmetic intensity vs float point performance \& memory performance.

    It lets you calculate if you need to work on improving the memory bandwidth or the float-point hardware.
}

\problem{
    w20q6q8
}{
    What does TLB do?
}{
    \pg{B-46} 

    To keep address translation in a special cache so that a memory access rarely requires a second access to translate the data.
}

\problem{
    w19f0q3
}{
    Does an average program's locality behavior stay the same while it is executing, or does it vary?
}{
    Vary
}

\problem{
    w20q6q1
}{
    What is \textit{2:1 cache rule of thumb}?
}{
    A directed mapped cache of size N has about the same miss rate as a two-way set associative cache of size N/2.
}

\problem{
    f13f0p3
    f16m2q1
    w19m2q3
    w20q6q7
}{
    Writes to a cache are inherently slower than reads from a cache. Why?
}{
    You can read the tag and simultaneously read the data location, Can discard the data read if the tag didn't match.
    However, you cannot do that on a write, because the write changes the state of the machine - you must first do the tag compare to ensure the write should, in fact change the state.

    \OR

    Read can do check tags and read data in parallel. 
    However, writing is inherently serial/sequential, so we have to check tags before writing the data to the cache. 
}

\problem{
    w13f0p1
    w15f0p1
    w19f0q5
}{
    Which type of cache miss can be reduced by using shorter lines?
}{
    Capacity
}
\problem{
    w13f0p1
    w15f0p1
    w19f0q6
}{
    Which type of cache miss can be reduced by using longer lines?
}{
    Compulsive
}
\problem{
    w13f0p1
    w15f0p1
    w19f0q7
}{
    Using a different mapping scheme will reduce which type of cache miss?
}{
    Conflict
}

\problem{
    w19f0q34
    w20q6q9
}{
    The designer has the choice of using a physically addressed cache or a virtually addressed cache.
    Explain the difference (drawing a picture is fine!), and give 1 advantage for each.
}{
    The virtually addressed cache is closer to CPU and doesn't need TLB to be addressed.
    Yet physically addressed cache has to be translated by TLB before it can be indexed.

    VA: Fasten \textbf{hit time}(don't need to go extra path to TLB)
    PA: Don't need to squash cache on \textbf{context switch}.
}

\problem{
    w20q6q2
}{
    LRU is a popular block replace scheme.
    However, true LRU is not used when the associativity becomes too high because it is difficuly to build true LRU.
    What are we using instead?
}{
    \pg{B-9}
    
    As the number of blocks to keep track of increases, LRU becomes increasingly expensive
    
    A common approximation called pesudo-LRU
}

\problem{
    w20q6q3
}{
    There are some hardware structures which do use true LRU.
    What is an example and why would designers do that?
}{
    TLB

    Because miss penalty is so huge that I am willing to do other things.
}

\problem{
    f13f0p8
    f15f0p7
    f16m2q16
    w19f0q52
    w20q6q10
}{
    Assuming a 19-bit address and a 256-byte Direct Mapped cache with a linesize=2, show how an address is partitioned/interpreted by the cache.
}{
    \begin{align*}
        & \texttt{offset} = 1 \texttt{bit }   \\
        & 256/2 = 128 =  2^7                  \\
        & \texttt{entry} = 7 \texttt{bits}    \\
        & \texttt{tag}  = 11\texttt{ bits}
    \end{align*}
}

\problem{
    f13f0p8
    f15f0p7
    f16m2q17
    w19f0q53
    w20q6q11
}{
    Assuming a 19-bit address and an 80-byte 10-way Set Associative cache with a linesize=4, show how an address is partitioned/interpreted by the cache.
}{
    \begin{align*}
        & \texttt{offset} = 2 \texttt{bits}   \\
        & 80/(10*4) = 2 = 2^1                 \\
        & \texttt{  set} = 1 \texttt{bit }    \\
        & \texttt{tag} = 16 \texttt{bits}
    \end{align*}
}

\problem{
    f13f0p8
    f15f0p7
    f16m2q18
    w19f0q54
    w20q6q12
}{
    Assuming a 19-bit address and a 328-byte Fully Associative cache with a linesize=8, show how an address is partitioned/interpreted by the cache.
}{
    \begin{align*}
        & \texttt{offset} =  3 \texttt{bits} \\
        & \texttt{tag   } = 16 \texttt{bits}        
    \end{align*}
}

\problem{
    f13f0p8
    f15f0p7
    f16m2q19
    w19f0q55
    w20q6q13
}{
    Given a 1 Megabyte physical memory, a 22-bit Virtual address, and a page size of 1K bytes, write down the number of entries in the Page Table, and the width of each entry.
}{
    \begin{align*}
        & 1M = 2^{20}; 1K = 2^{10} \\
        & (2^{20})/(2^{10}) = 2^{10} \rightarrow \texttt{10-bit wide }
    \end{align*}
    PM: $ 10 | 10 $ \\
    VM: $ 12 | 10 $ \\
    $2^{12}$ \texttt{entries}        
}

\problem{
    f13f0p8
    f15f0p7
    f16m2q20
    w19f0q56
    w20q6q14
}{
    Given a 1 Megabyte physical memory, a 34-bit Virtual address, and a page size of 2K bytes, write down the number of entries in the Page Table, and the width of each entry. Is there a problem with this configuration? 
    If so, what is the problem?
}{
    \begin{align*}
        & 1M = 2^{20}; 2K = 2^{11} \\
        & (2^{20})/(2^{11}) = 2^9 \rightarrow \texttt{ 9-bit wide }
    \end{align*}
    PM: $  9 | 11 $ \\
    VM: $ 23 | 11 $ \\
    $2^{23}$ \texttt{entries}         \\
    Problem: It is too large to store in 1M physical memory. 
    We can use two page tables. One is base, another one is secondary.
}